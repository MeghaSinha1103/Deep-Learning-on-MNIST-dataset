# Deep-Learning-on-MNIST-dataset

This assignment was done to prepare images and perform classification on the fashion-MNIST dataset in order to gain some idea on what are the different parameters that can be changed and to understand what is the meaning of the hyperparameters which are changed during performing the experiment. Optimizers used were adam, nadam, adagrad, and SGD. Parameters which were changed - epoch, batch size, dense layer, learning rate, convolutional layers, max-pooling layer, drop out layer
